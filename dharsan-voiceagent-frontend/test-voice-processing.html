<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Processing Test</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
            background-color: #1a1a1a;
            color: #ffffff;
        }
        .test-section {
            margin: 20px 0;
            padding: 20px;
            border: 1px solid #333;
            border-radius: 8px;
            background-color: #2a2a2a;
        }
        .success { border-color: #4CAF50; background-color: #1e3a1e; }
        .error { border-color: #f44336; background-color: #3a1e1e; }
        .processing { border-color: #ff9800; background-color: #3a2e1e; }
        .info { border-color: #2196F3; background-color: #1e3a3a; }
        
        button {
            background-color: #4CAF50;
            color: white;
            padding: 12px 24px;
            border: none;
            border-radius: 6px;
            cursor: pointer;
            margin: 8px;
            font-size: 14px;
            font-weight: bold;
        }
        button:hover { background-color: #45a049; }
        button:disabled { background-color: #666; cursor: not-allowed; }
        button.recording { background-color: #f44336; animation: pulse 1s infinite; }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.7; }
            100% { opacity: 1; }
        }
        
        .log {
            background-color: #1a1a1a;
            padding: 15px;
            border-radius: 6px;
            font-family: 'Courier New', monospace;
            font-size: 12px;
            max-height: 300px;
            overflow-y: auto;
            margin-top: 15px;
            border: 1px solid #444;
        }
        
        .status-indicator {
            display: inline-block;
            width: 16px;
            height: 16px;
            border-radius: 50%;
            margin-right: 10px;
        }
        .status-connected { background-color: #4CAF50; }
        .status-disconnected { background-color: #f44336; }
        .status-connecting { background-color: #ff9800; }
        .status-processing { background-color: #2196F3; }
        
        .grid {
            display: grid;
            grid-template-columns: 1fr 1fr;
            gap: 20px;
        }
        
        .audio-visualizer {
            width: 100%;
            height: 80px;
            background-color: #1a1a1a;
            border-radius: 6px;
            display: flex;
            align-items: center;
            justify-content: center;
            margin: 15px 0;
            border: 1px solid #444;
        }
        
        .transcript-display {
            background-color: #1a1a1a;
            padding: 15px;
            border-radius: 6px;
            min-height: 100px;
            border: 1px solid #444;
            margin: 15px 0;
        }
        
        .metrics {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(150px, 1fr));
            gap: 10px;
            margin: 15px 0;
        }
        
        .metric {
            background-color: #1a1a1a;
            padding: 10px;
            border-radius: 4px;
            text-align: center;
            border: 1px solid #444;
        }
        
        .metric-value {
            font-size: 18px;
            font-weight: bold;
            color: #4CAF50;
        }
        
        .metric-label {
            font-size: 12px;
            color: #888;
            margin-top: 5px;
        }
    </style>
</head>
<body>
    <h1>üé§ Voice Processing Test</h1>
    <p>Comprehensive test of speech recognition, AI processing, and text-to-speech</p>
    
    <div class="grid">
        <div class="test-section">
            <h3>üîó Connection Status</h3>
            <div>
                <span class="status-indicator status-disconnected" id="connection-status"></span>
                <span id="connection-text">Disconnected</span>
            </div>
            <button onclick="connectToBackend()">Connect to Backend</button>
            <button onclick="disconnectFromBackend()">Disconnect</button>
            <div id="connection-log" class="log"></div>
        </div>
        
        <div class="test-section">
            <h3>üéµ Audio Input Test</h3>
            <button id="mic-button" onclick="toggleMicrophone()">Start Microphone</button>
            <button onclick="testAudioOutput()">Test Audio Output</button>
            <div class="audio-visualizer" id="audio-visualizer">
                <span>Audio Visualizer</span>
            </div>
            <div id="audio-log" class="log"></div>
        </div>
    </div>
    
    <div class="test-section">
        <h3>üí¨ Voice Processing Pipeline</h3>
        <button id="voice-test-button" onclick="startVoiceTest()" disabled>Start Voice Test</button>
        <button onclick="stopVoiceTest()">Stop Test</button>
        <button onclick="clearAllLogs()">Clear Logs</button>
        
        <div class="metrics">
            <div class="metric">
                <div class="metric-value" id="audio-chunks">0</div>
                <div class="metric-label">Audio Chunks</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="voice-activity">0%</div>
                <div class="metric-label">Voice Activity</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="processing-time">0ms</div>
                <div class="metric-label">Processing Time</div>
            </div>
            <div class="metric">
                <div class="metric-value" id="messages-received">0</div>
                <div class="metric-label">Messages</div>
            </div>
        </div>
        
        <div id="voice-log" class="log"></div>
    </div>
    
    <div class="grid">
        <div class="test-section">
            <h3>üìù Speech Recognition Results</h3>
            <div class="transcript-display" id="transcript-display">
                <em>No transcript yet...</em>
            </div>
            <div id="transcript-log" class="log"></div>
        </div>
        
        <div class="test-section">
            <h3>ü§ñ AI Response Results</h3>
            <div class="transcript-display" id="ai-response-display">
                <em>No AI response yet...</em>
            </div>
            <div id="ai-log" class="log"></div>
        </div>
    </div>
    
    <div class="test-section">
        <h3>üîç Test Scenarios</h3>
        <button onclick="runTestScenario('greeting')">Test: "Hello, how are you?"</button>
        <button onclick="runTestScenario('weather')">Test: "What's the weather like?"</button>
        <button onclick="runTestScenario('math')">Test: "What is 15 plus 27?"</button>
        <button onclick="runTestScenario('joke')">Test: "Tell me a joke"</button>
        <button onclick="runTestScenario('custom')">Custom Test</button>
        <div id="scenario-log" class="log"></div>
    </div>

    <script>
        const BACKEND_URL = 'https://dharsan99--voice-ai-backend-run-app.modal.run';
        let websocket = null;
        let audioContext = null;
        let mediaStream = null;
        let audioProcessor = null;
        let isRecording = false;
        let isConnected = false;
        
        // Metrics
        let audioChunksSent = 0;
        let voiceActivityLevel = 0;
        let processingTime = 0;
        let messagesReceived = 0;
        
        function log(message, logId) {
            const logElement = document.getElementById(logId);
            const timestamp = new Date().toLocaleTimeString();
            logElement.innerHTML += `[${timestamp}] ${message}\n`;
            logElement.scrollTop = logElement.scrollHeight;
        }
        
        function clearAllLogs() {
            ['connection-log', 'audio-log', 'voice-log', 'transcript-log', 'ai-log', 'scenario-log'].forEach(id => {
                document.getElementById(id).innerHTML = '';
            });
        }
        
        function updateStatus(status, text) {
            const statusElement = document.getElementById('connection-status');
            const textElement = document.getElementById('connection-text');
            statusElement.className = `status-indicator status-${status}`;
            textElement.textContent = text;
        }
        
        function updateMetrics() {
            document.getElementById('audio-chunks').textContent = audioChunksSent;
            document.getElementById('voice-activity').textContent = `${Math.round(voiceActivityLevel * 100)}%`;
            document.getElementById('processing-time').textContent = `${processingTime}ms`;
            document.getElementById('messages-received').textContent = messagesReceived;
        }
        
        async function connectToBackend() {
            try {
                log('Connecting to backend...', 'connection-log');
                updateStatus('connecting', 'Connecting...');
                
                websocket = new WebSocket(`${BACKEND_URL.replace('https://', 'wss://')}/ws`);
                
                websocket.onopen = () => {
                    log('‚úÖ Connected to backend successfully!', 'connection-log');
                    updateStatus('connected', 'Connected');
                    isConnected = true;
                    document.getElementById('voice-test-button').disabled = false;
                };
                
                websocket.onmessage = (event) => {
                    messagesReceived++;
                    updateMetrics();
                    
                    if (typeof event.data === 'string') {
                        log(`üì• Received: ${event.data}`, 'voice-log');
                        
                        try {
                            const message = JSON.parse(event.data);
                            handleMessage(message);
                        } catch (error) {
                            // Handle plain text messages
                            if (event.data.includes('received:')) {
                                log('üîÑ Audio echo received', 'voice-log');
                            } else {
                                log(`üìù Plain text: ${event.data}`, 'voice-log');
                            }
                        }
                    } else if (event.data instanceof Blob) {
                        log(`üéµ Audio chunk received: ${event.data.size} bytes`, 'voice-log');
                        playAudioChunk(event.data);
                    }
                };
                
                websocket.onclose = (event) => {
                    log(`üîå Connection closed: ${event.code}`, 'connection-log');
                    updateStatus('disconnected', 'Disconnected');
                    isConnected = false;
                    document.getElementById('voice-test-button').disabled = true;
                };
                
                websocket.onerror = (error) => {
                    log(`‚ùå Connection error: ${error}`, 'connection-log');
                    updateStatus('disconnected', 'Error');
                };
                
            } catch (error) {
                log(`‚ùå Failed to connect: ${error.message}`, 'connection-log');
                updateStatus('disconnected', 'Failed');
            }
        }
        
        function disconnectFromBackend() {
            if (websocket) {
                websocket.close();
                websocket = null;
            }
            if (isRecording) {
                stopMicrophone();
            }
        }
        
        function handleMessage(message) {
            const startTime = performance.now();
            
            switch (message.type) {
                case 'transcript':
                    log(`üé§ Transcript: ${message.text}`, 'transcript-log');
                    document.getElementById('transcript-display').innerHTML = `
                        <strong>Transcript:</strong><br>
                        ${message.text}<br>
                        <small>Confidence: ${Math.round((message.confidence || 0.9) * 100)}%</small>
                    `;
                    break;
                    
                case 'ai_response':
                    log(`ü§ñ AI Response: ${message.response}`, 'ai-log');
                    document.getElementById('ai-response-display').innerHTML = `
                        <strong>AI Response:</strong><br>
                        ${message.response}<br>
                        <small>Processing time: ${message.processing_time_ms || 0}ms</small>
                    `;
                    break;
                    
                case 'error':
                    log(`‚ùå Error: ${message.message}`, 'voice-log');
                    break;
                    
                default:
                    log(`üì® Unknown message type: ${message.type}`, 'voice-log');
            }
            
            processingTime = Math.round(performance.now() - startTime);
            updateMetrics();
        }
        
        async function toggleMicrophone() {
            if (isRecording) {
                stopMicrophone();
            } else {
                await startMicrophone();
            }
        }
        
        async function startMicrophone() {
            try {
                log('Requesting microphone access...', 'audio-log');
                
                mediaStream = await navigator.mediaDevices.getUserMedia({
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    }
                });
                
                log('‚úÖ Microphone access granted', 'audio-log');
                
                // Create audio context
                audioContext = new AudioContext({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(mediaStream);
                
                // Create audio processor
                try {
                    await audioContext.audioWorklet.addModule('/audio-processor.js');
                    audioProcessor = new AudioWorkletNode(audioContext, 'audio-processor');
                } catch (error) {
                    log(`‚ö†Ô∏è Audio worklet failed, using fallback: ${error.message}`, 'audio-log');
                    // Fallback: create a simple audio processor
                    audioProcessor = createSimpleAudioProcessor(audioContext);
                }
                
                audioProcessor.port.onmessage = (event) => {
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        audioChunksSent++;
                        updateMetrics();
                        
                        // Send audio data
                        websocket.send(event.data.audioData);
                        
                        // Update voice activity
                        voiceActivityLevel = event.data.voiceActivity || 0;
                        updateMetrics();
                        
                        // Update visualizer
                        updateAudioVisualizer(voiceActivityLevel);
                    }
                };
                
                source.connect(audioProcessor);
                isRecording = true;
                
                const micButton = document.getElementById('mic-button');
                micButton.textContent = 'Stop Microphone';
                micButton.className = 'recording';
                
                log('üé§ Microphone started - speaking now...', 'audio-log');
                
            } catch (error) {
                log(`‚ùå Microphone error: ${error.message}`, 'audio-log');
            }
        }
        
        function stopMicrophone() {
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            if (audioProcessor) {
                audioProcessor.disconnect();
                audioProcessor = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            isRecording = false;
            voiceActivityLevel = 0;
            updateMetrics();
            
            const micButton = document.getElementById('mic-button');
            micButton.textContent = 'Start Microphone';
            micButton.className = '';
            
            document.getElementById('audio-visualizer').style.background = '#1a1a1a';
            
            log('üõë Microphone stopped', 'audio-log');
        }
        
        function updateAudioVisualizer(activity) {
            const visualizer = document.getElementById('audio-visualizer');
            const intensity = Math.min(activity * 100, 100);
            visualizer.style.background = `linear-gradient(90deg, #4CAF50 ${intensity}%, #1a1a1a ${intensity}%)`;
        }
        
        async function testAudioOutput() {
            try {
                log('Testing audio output...', 'audio-log');
                
                if (!audioContext) {
                    audioContext = new AudioContext();
                }
                
                // Create test tone
                const oscillator = audioContext.createOscillator();
                const gainNode = audioContext.createGain();
                
                oscillator.connect(gainNode);
                gainNode.connect(audioContext.destination);
                
                oscillator.frequency.setValueAtTime(440, audioContext.currentTime);
                gainNode.gain.setValueAtTime(0.1, audioContext.currentTime);
                
                oscillator.start(audioContext.currentTime);
                oscillator.stop(audioContext.currentTime + 0.5);
                
                log('‚úÖ Audio output test completed (should hear a beep)', 'audio-log');
                
            } catch (error) {
                log(`‚ùå Audio output error: ${error.message}`, 'audio-log');
            }
        }
        
        function startVoiceTest() {
            if (!isConnected) {
                log('‚ùå Not connected to backend', 'voice-log');
                return;
            }
            
            log('üé§ Starting voice processing test...', 'voice-log');
            log('Speak clearly into your microphone', 'voice-log');
            log('Try saying: "Hello, how are you?"', 'voice-log');
        }
        
        function stopVoiceTest() {
            log('üõë Voice test stopped', 'voice-log');
        }
        
        async function playAudioChunk(blob) {
            try {
                const arrayBuffer = await blob.arrayBuffer();
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
                log('üîä Playing audio chunk', 'voice-log');
            } catch (error) {
                log(`‚ùå Audio playback error: ${error.message}`, 'voice-log');
            }
        }
        
        function runTestScenario(scenario) {
            const scenarios = {
                greeting: "Hello, how are you today?",
                weather: "What's the weather like in San Francisco?",
                math: "What is 15 plus 27?",
                joke: "Tell me a funny joke",
                custom: prompt("Enter your test phrase:")
            };
            
            const testPhrase = scenarios[scenario];
            if (!testPhrase) return;
            
            log(`üß™ Running test scenario: "${testPhrase}"`, 'scenario-log');
            
            // Simulate sending this as audio data
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                // Send a test message
                websocket.send(JSON.stringify({
                    type: 'test_phrase',
                    text: testPhrase
                }));
                log(`üì§ Sent test phrase to backend`, 'scenario-log');
            } else {
                log(`‚ùå Not connected to backend`, 'scenario-log');
            }
        }
        
        function createSimpleAudioProcessor(audioContext) {
            // Create a simple script processor as fallback
            const bufferSize = 1024;
            const processor = audioContext.createScriptProcessor(bufferSize, 1, 1);
            
            processor.onaudioprocess = (event) => {
                const inputBuffer = event.inputBuffer;
                const inputData = inputBuffer.getChannelData(0);
                
                // Calculate energy for voice activity detection
                let energy = 0;
                for (let i = 0; i < inputData.length; i++) {
                    energy += inputData[i] * inputData[i];
                }
                energy = Math.sqrt(energy / inputData.length);
                
                // Simple voice activity detection
                const isVoiceActive = energy > 0.01;
                
                // Convert to 16-bit PCM
                const audioData = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    audioData[i] = Math.max(-32768, Math.min(32767, inputData[i] * 32767));
                }
                
                // Simulate the worklet message format
                const message = {
                    audioData: audioData.buffer,
                    voiceActivity: isVoiceActive,
                    energy: energy
                };
                
                // Trigger the same handler as the worklet
                if (typeof audioProcessor.port !== 'undefined' && audioProcessor.port.onmessage) {
                    audioProcessor.port.onmessage({ data: message });
                }
            };
            
            return processor;
        }
        
        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            disconnectFromBackend();
        });
        
        // Initialize
        updateStatus('disconnected', 'Disconnected');
        updateMetrics();
    </script>
</body>
</html> 